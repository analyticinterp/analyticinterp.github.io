---
title: "Want to understand hyperparameter selection (and why should theorists care)?"
toc_title: "ðŸš§ ...hyperparameter selection (and why should theorists care)?"
author: "[long list of authors]"
date: "2025-09-01"
description: "The theoretical foundations of hyperparameter optimization and its importance for understanding deep learning."
sequence: "quickstart"
sequence_title: "A Quickstart Guide to Learning Mechanics"
sequence_description: "A comprehensive guide to understanding the mathematical foundations of deep learning, from optimization to generalization."
sequence_order: 3
---

[TO BE WRITTEN]

- to understand anything in DL, youâ€™ll want to run experiments. your experiments will involve HPs. if you donâ€™t understand how they affect your system, theyâ€™ll confound your result.
- itâ€™s HPs that make understanding DL hard. is architecture A or B better? is dataset C or D easier to learn? well, you canâ€™t tell unless you meta-optimize over HPs. the difficulties that HPs present practice are redoubled for theory. itâ€™s thus indispensable that you study them.
- there are usually more HPs than you even realized were there.

- muP
    - first breakout success of DL theory; took a while

Blake to write the rest of this one?

- |B| scaling w Î·
- description of paper, I didnâ€™t quite understand it; |B| vs Î· vs. model size?: https://arxiv.org/abs/2410.21676
- Canonical batch size lr paper SGD: https://arxiv.org/abs/1812.06162
- Later SDE paper handles Adam: https://arxiv.org/abs/2205.10287