---
lang: en
---

Analytic Interpretability is a team of scientist scattered all over the world trying to understand the mysteries of deep learning. As Jamie put it, we’re all exploring a big maze, looking for the exit. Most people in our field are wandering around rather unproductively (or are carefully mapping regions of the maze we know don’t contain the exit). A few of us have been earnestly exploring the maze for several years now and have good ideas for promising places to look next. It makes sense to develop a collective map of the regions we’ve explored, flag the crucial splits, and start saying “you go left, I’ll go right, report back.”

The team is made up of various PhD students/postdocs/profs:

- [Alex Atanasov](https://abatanasov.com/)
- [Jeremy Bernstein](https://jeremybernste.in/)
- [Blake Bordelon](https://blakebordelon.github.io/)
- [Jeremy Cohen](https://jmcohen.github.io/)
- [Alex Damian](https://web.math.princeton.edu/~ad27/)
- [Nikhil Ghosh](https://nikhil-ghosh-berkeley.github.io/)
- [Florentin Guth](https://florentinguth.github.io/)
- [Arthur Jacot](https://sites.google.com/view/arthurjacot)
- [Dhruva Karkada](https://dkarkada.xyz/)
- [Daniel Kunin](https://daniel-kunin.com/)
- [Alex Meterez](https://alexandrumeterez.github.io/)
- [Eric Michaud](https://ericjmichaud.com/)
- [Theodor Misiakiewicz](https://misiakie.github.io/)
- [Berkan Ottlik](https://berkan.xyz/)
- [Adit Radha](https://aditradha.com/)
- [Jamie Simon](https://james-simon.github.io/)
- [Joey Turnbull](https://www.linkedin.com/in/joey-turnbull/)
- [Jacob Zavatone-Veth](https://jzv.io/)